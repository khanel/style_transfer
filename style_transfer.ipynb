{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook is an implementation of this paper titled ['Image Style Transfer Using Convolutional Neural Network'](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf). However, please note that my implementation will not cover all aspects presented in the paper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before delving into the paper, let's first examine the output of the convolutional layers in a trained Convolutional Neural Network (CNN). For this purpose, we will use the pre-trained VGG19 model.\n",
    "First of all, we'll begin by adding the necessary packages to our project. We'll fetch the VGG19 model with pre-trained weights, which can be easily obtained using the torchvision package in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained VGG19 model\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "vgg19.eval()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
